trainer:
  gpu: 0
  workers: 4
  print_freq: 100
dir:
  output_dir: output
  log_dir: log
dataset:
  name: mpii
  path:
    root: /data/${name}/
    test: valid_half
    train: train
  pipelines:
    load_image:
      _target_: pipelines.LoadImageFromFile
    get_random_scale_rotation:
      _target_: pipelines.TopDownGetRandomScaleRotation
      scale_factor: 0.25
      rotation_factor: 30
    random_flip:
      _target_: pipelines.TopDownRandomFlip
      flip_probs: 0.5
      # is_flip: True
    half_body_transform:
      _target_: pipelines.TopDownHalfBodyTransform
      num_joints_half_body: 8
      prob_half_body: 0.3
      upper_body_ids: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
      image_size: ???
    affine_transform:
      _target_: pipelines.TopDownAffine
      use_udp: True
      image_size: ???
    generate_heatmap:
      _target_: pipelines.TopDownGenerateHeatmap
      sigma: 2
      heatmap_type: gaussian
      image_size: ???
      heatmap_size: ???
    get_augmentation:
      _target_: ??? # augmentation class하나 만들고, 거기에 cutmix, cutout 등등 함수로 넣어놓고, 인자에 따라서 call할 수 있게 하기.
task:
  _target_: ??? # maybe fedavg, fedprox? or SFLTrainer?? #

















FED:
  FEDAVG: False
  FEDPROX: True

KD_USE: True

MODEL:
  INIT_WEIGHTS: true
  NAME: vit
  TYPE: 'small'

  # NUM_JOINTS: 17
  NUM_JOINTS: 16
  # PRETRAINED: 'checkpoints/vitpose_large.pth'
  PRETRAINED: 'checkpoints/mae_pretrain_vit_small.pth'
  
  # Multi-Resolution을 위한 셋팅
  IMAGE_SIZE:
  -
    - 192
    - 256
  -
    - 144
    - 192
  -
    - 96
    - 128
  HEATMAP_SIZE:
  -
    - 48
    - 64
  -
    - 36
    - 48
  -
    - 24
    - 32

  # FREEZE_NAME:
  # - "backbone"
  # - "keypoint_head"
  SCALE: 1
  USE_AFTER_KP_HEAD: false 
  SUM_TO_ONE: true
  USE_EXP_KP: False

  USE_GPE: true
  USE_LPE: true
  # USE_GAP: true

  # KD_TARGET: "cls"
  KD_TARGET: "logit_hm"

LOSS:
  HM_LOSS: "JointMSEloss"
  # HM_LOSS: "CEloss"
  # UNC_LOSS: "SoftPlusloss"
  # KD_LOSS: "DistillationLoss"
  # KD_LOSS: "JointMSEloss"

  USE_TARGET_WEIGHT: true
  UNCERTAINTY: false
  NORMALIZED_MAP: false  
  USE_INDEXING: true
  
  HM_LOSS_WEIGHT: 1
  KP_LOSS_WEIGHT: 0.0001
  KD_LOSS_WEIGHT: 1
  
  KD_TAU: 1.0
  KD_TYPE: "smooth-l1" # soft, cosine, l2, None

TRAIN:
  BATCH_SIZE: 32
  SHUFFLE: true
  BEGIN_EPOCH: 0
  # BEGIN_EPOCH: 150
  END_EPOCH: 211
  RESUME: false
  # RESUME: True

  OPTIMIZER: 'adamW'
  # LR: 0.0000625
  # LR: 0.000125
  # LR: 0.0005 # 분산학습할 때는 여기에서 GPU 수만큼 나눠줘야 함.
  LR: 0.00025
  # LR: 0.002
  LR_FACTOR: 0.1
  LR_STEP:
  - 170
  - 200
  WD: 0.01
  GAMMA1: 0.99
  GAMMA2: 0.0
  MOMENTUM: 0.9
  NESTEROV: false

  # USE_PROXY: True
  USE_PROXY: false

TEST:
  BATCH_SIZE: 64
  COCO_BBOX_FILE: 'data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'
  FLIP_TEST: true
  IMAGE_THRE: 0.0
  IN_VIS_THRE: 0.2
  MODEL_FILE: ''
  NMS_THRE: 1.0
  OKS_THRE: 0.9
  USE_GT_BBOX: False
  USE_UDP : True 
  MODULATE_KERNEL: 11
  SHIFT_TEST: False
  SHIFT_HEATMAP: False


EVALUATION:
  INTERVAL: 10
  METRIC: 'mAP'
  SAVE_BEST: 'AP'

# DEBUG:
#   SAVE_BATCH_IMAGES_GT: True
#   SAVE_BATCH_IMAGES_PRED: True
#   SAVE_HEATMAPS_GT: True
#   SAVE_HEATMAPS_PRED: True

DATA_DIR: ''

DATASET_SETS:
  -
    DATASET: 'mpii'
    ROOT: 'data/mpii/'
    TEST_SET: 'valid_half'
    TRAIN_SET: 'train'
  -
    DATASET: 'mpii'
    ROOT: 'data/mpii/'
    TEST_SET: 'valid_half'
    TRAIN_SET: 'train'
  -
    DATASET: 'mpii'
    ROOT: 'data/mpii/'
    TEST_SET: 'valid_half'
    TRAIN_SET: 'train'

DATASET_PROXY:
  DATASET: 'mpii_split_proxy'
  ROOT: 'data/mpii_split_proxy/'
  TEST_SET: 'valid_half'
  TRAIN_SET: 'train_proxy'

DATASET:
  TARGET_KEYPOINT: True
  TARGET_HEATMAP: True
  CUTMIX: True
  CUTOUT: False
  SAME_POS: True
  CLEAN_HIGH: True
  NUMBER_OF_SPLITS: 1